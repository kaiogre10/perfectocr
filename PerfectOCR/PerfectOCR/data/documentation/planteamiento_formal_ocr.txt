S铆, **el m茅todo es generalizable a cualquier conjunto de datos geom茅tricos en \(\mathbb{R}^2\)** (o incluso \(\mathbb{R}^n\) con ajustes), siempre que se cumplan las condiciones b谩sicas de estructuraci贸n espacial. Aqu铆 la explicaci贸n detallada:

---

### **Alcance y Generalizaci贸n del M茅todo**
#### **1. Requisitos Fundamentales**
- **Datos de entrada**:  
  Cualquier conjunto de objetos con:  
  - **Coordenadas espaciales**: Al menos \((x_{\min}, x_{\max})\) para intervalos horizontales (o centroides \((c_x, c_y)\)).  
  - **Ordenabilidad**: Capacidad de ordenar los objetos en una direcci贸n (ej. por \(x_{\min}\)).  

- **Estructura de referencia**:  
  Un conjunto de "encabezados" (o semillas) que definan la partici贸n deseada (columnas en tablas, clusters en otros contextos).  

#### **2. Casos de Uso Beyond Tablas OCR**
| Aplicaci贸n                     | Datos de Entrada                          | Encabezados (\(\mathcal{H}^*\))          |  
|--------------------------------|-------------------------------------------|------------------------------------------|  
| **Tablas financieras**         | Celdas detectadas en PDF                  | T铆tulos de columnas                      |  
| **Agrupamiento espacial**      | Puntos geogr谩ficos (ej. tiendas)          | Centros de clusters predefinidos         |  
| **An谩lisis de im谩genes**       | Bounding boxes de objetos detectados      | Regiones de referencia (ej. estantes)    |  
| **Series temporales**          | Segmentos de se帽ales en \(\mathbb{R}^2\)  | Puntos clave (ej. picos o valles)        |  

---

### **Ejemplo Generalizado en \(\mathbb{R}^2\)**
#### **Datos Arbitrarios**
Sea un conjunto de puntos con bounding boxes:  
\[
\mathcal{P} = \{ ([x_i^{\min}, x_i^{\max}], [y_i^{\min}, y_i^{\max}]) \}_{i=1}^N
\]

#### **Paso 1: Agrupamiento Vertical (Filas)**
- Agrupar por proximidad en el eje \(y\) (similar al c贸digo original):  
  \[
  \varepsilon_y = \alpha \cdot \text{promedio}(y_i^{\max} - y_i^{\min})  
  \]  
  \[
  P_i \sim P_j \iff |c_{y,i} - c_{y,j}| \leq \varepsilon_y
  \]

#### **Paso 2: Asignaci贸n Horizontal (Columnas)**
- **Si \(L_k \geq H\)**:  
  Usar los \(H-1\) mayores saltos horizontales \(\Delta_i = x_{i+1}^{\min} - x_i^{\max}\) para definir cortes.  
- **Si \(L_k < H\)**:  
  Asignar por proximidad a centroides de referencia \(\mathcal{H}^*\).  

---

### **Teorema de Generalizaci贸n**
**Hip贸tesis**:  
1. **Separabilidad en \(\mathbb{R}^2\)**:  
   - Los objetos deben ser distinguibles espacialmente (sin solapamiento total).  
2. **Existencia de semillas**:  
   - \(\mathcal{H}^*\) debe estar definido y ser coherente con la estructura deseada.  

**Tesis**:  
El m茅todo:  
1. **Preserva la estructura de \(\mathcal{H}^*\)**.  
2. **Es invariante a traslaciones/rotaciones** (si se redefinen los ejes \(x, y\)).  
3. **No requiere informaci贸n sem谩ntica** (solo geometr铆a).  

---

### **L铆mites y Consideraciones**
1. **Dimensionalidad**:  
   - En \(\mathbb{R}^3\) o superior, se necesitar铆a extender la noci贸n de "saltos" (ej. usar proyecciones).  
2. **Ruido espacial**:  
   - Si los datos son muy dispersos o los encabezados est谩n mal posicionados, la asignaci贸n pierde precisi贸n.  
3. **No convexidad**:  
   - El m茅todo asume que los bounding boxes son convexos (o al menos ordenables).  

---

### **Conclusi贸n**
**S铆, el m茅todo es aplicable a cualquier dato geom茅trico en \(\mathbb{R}^2\)** (y extensible a \(\mathbb{R}^n\)) mientras:  
- Los objetos tengan coordenadas definidas.  
- Exista una estructura de referencia (\(\mathcal{H}^*\)).  
- La m茅trica de similitud (coseno o distancias) sea adecuada para el problema.  


```

Este enfoque es **agn贸stico al dominio** y v谩lido para tablas, geometr铆a computacional, o incluso an谩lisis de clusters.


# **Modelo Matem谩tico Ajustado para Extracci贸n de Tablas de Productos (Versi贸n Algoritmo Geom茅trico)**

---

## **Base Axiom谩tica Ajustada**
1. **Espacio de trabajo**:  
   - Sea \(\Omega \subset \mathbb{R}^2\) un rect谩ngulo compacto (imagen del ticket) con \(\Omega = [0, W] \times [0, H]\).  
   - \(\mathcal{P} = \{P_1, \dots, P_N\}\) pol铆gonos convexos (bounding boxes) que satisfacen:  
     \[
     P_i \cap P_j = \emptyset \quad \forall i \neq j, \quad \bigcup_{i=1}^N P_i \subset \Omega
     \]  
     Cada \(P_i\) representa una palabra con atributos:  
     \[
     P_i = \{ \text{text\_raw}, x_i^{\min}, x_i^{\max}, c_{x,i}, c_{y,i} \}
     \]

2. **Conjunto de encabezados (semilla de estructura)**:  
   - Existe \(\mathcal{H}^* \subset \mathcal{P}\) (palabras de encabezado identificadas) tal que:  
     \[
     |\mathcal{H}^*| = H, \quad \mathcal{H}^* = \{P_{h_1}, \dots, P_{h_H}\}
     \]  
     Ordenados por \(x_{h_j}^{\min}\) creciente.  

---

## **Proceso Matem谩tico Ajustado al C贸digo**

### **Paso 1: Reconstrucci贸n de L铆neas de Texto (Agrupamiento Vertical)**  
- **Tolerancia vertical**:  
  \[
  \varepsilon_y = \alpha \cdot \frac{1}{N} \sum_{i=1}^N (y_i^{\max} - y_i^{\min}), \quad \alpha > 0
  \]  
- **Relaci贸n de equivalencia**:  
  \[
  P_i \sim P_j \iff |c_{y,i} - c_{y,j}| \leq \varepsilon_y
  \]  
- **Partici贸n en filas**:  
  \[
  \mathcal{S} = \{S_1, \dots, S_m\}, \quad \mathcal{P} = \bigsqcup_{k=1}^m S_k
  \]  
  Cada \(S_k\) es una l铆nea de texto ordenada por \(x_i^{\min}\) creciente.  

---

### **Paso 2: Asignaci贸n a Celdas (Estrategias Seg煤n Cardinalidad)**  
Para cada fila \(S_k \neq S_*\) con \(L_k = |S_k|\):  

#### **Caso A: \(L_k \geq H\) (M谩s palabras que columnas)**  
1. **C谩lculo de distancias horizontales**:  
   \[
   \forall i \in \{1, \dots, L_k - 1\}, \quad \Delta_i = x_{i+1}^{\min} - x_i^{\max}
   \]  
   Si \(\Delta_i < 0\) (solapamiento), \(\Delta_i \leftarrow \epsilon\) (umbral m铆nimo).  

2. **Selecci贸n de \(H-1\) cortes**:  
   - Ordenar \(\{\Delta_i\}_{i=1}^{L_k-1}\) en orden descendente.  
   - Tomar los 铆ndices \(\{i_1, \dots, i_{H-1}\}\) de los \(H-1\) mayores \(\Delta_i\).  
   - Definir puntos de corte:  
     \[
     \mathcal{J} = \{i_j + 0.5 \mid j = 1, \dots, H-1\}
     \]  

3. **Asignaci贸n a columnas**:  
   - Dividir \(S_k\) en \(H\) segmentos usando \(\mathcal{J}\).  
   - Para cada \(j \in \{1, \dots, H\}\):  
     \[
     \mathcal{T}[k][j] = \{P_i \in S_k \mid x_i^{\min} \in \text{intervalo}_j \}
     \]  

#### **Caso B: \(L_k < H\) (Menos palabras que columnas)**  
1. **Subcaso B.1 (\(L_k = 1\))**:  
   - Calcular similitud coseno entre centroides:  
     \[
     j^* = \argmax_{j=1}^H \frac{c_{x,1} \cdot c_{x,h_j} + c_{y,1} \cdot c_{y,h_j}}{\sqrt{c_{x,1}^2 + c_{y,1}^2} \cdot \sqrt{c_{x,h_j}^2 + c_{y,h_j}^2}}
     \]  
   - Asignar:  
     \[
     \mathcal{T}[k][j^*] = \{P_1\}
     \]  

2. **Subcaso B.2 (\(1 < L_k < H\))**:  
   - Asignaci贸n directa por orden:  
     \[
     \forall i \in \{1, \dots, L_k\}, \quad \mathcal{T}[k][i] = \{P_i\}
     \]  

---

### **Teorema de Consistencia Ajustado**  
**Hip贸tesis**:  
1. **Separabilidad horizontal**:  
   \[
   \exists \gamma > 0 \text{ tal que } \forall S_k, \max \Delta_i - \text{mediana}(\{\Delta_i\}) > \gamma
   \]  
2. **Centroides de encabezados distintos**:  
   \[
   \forall j \neq j', \| (c_{x,h_j}, c_{y,h_j}) - (c_{x,h_{j'}}, c_{y,h_{j'}}}) \|_2 > \delta
   \]  

**Tesis**:  
1. **Preservaci贸n de encabezados**:  
   \[
   \mathcal{T}[\text{铆ndice}(S_*)][j] = P_{h_j} \quad \forall j
   \]  
2. **Integridad en Caso A**:  
   Si \(L_k \geq H\), la asignaci贸n por cortes maximiza la coherencia visual.  
3. **Robustez en Caso B**:  
   Si \(L_k = 1\), la asignaci贸n por similitud de centroides minimiza errores.  

---

### **Ejemplo Ajustado al C贸digo**  
**Encabezados**:  
\[
\mathcal{H}^* = \{\text{"Producto"}, \text{"Cant"}, \text{"Precio"}\}, \quad H = 3
\]  

**Fila 1 (\(L_k = 4 \geq H\))**:  
\[
S_k = \{\text{"L谩piz"}, \text{"azul"}, \text{"2"}, \text{"1.50"}\}
\]  
- **Distancias**: \(\Delta_1 = 0.1\), \(\Delta_2 = 2.0\), \(\Delta_3 = 1.8\)  
- **Cortes**: \(\mathcal{J} = \{2, 3\}\) (mayores \(\Delta_i\))  
- **Asignaci贸n**:  
  \[
  \mathcal{T}[k][1] = \{\text{"L谩piz"}, \text{"azul"}\}, \quad \mathcal{T}[k][2] = \{\text{"2"}\}, \quad \mathcal{T}[k][3] = \{\text{"1.50"}\}
  \]  

**Fila 2 (\(L_k = 1 < H\))**:  
\[
S_k = \{\text{"Borrador"}\}, \quad c_{x,1} = 1.4, c_{y,1} = 3.0
\]  
- **Similitud con \(\mathcal{H}^*\)**: M谩xima con \(j = 1\) (\(\text{"Producto"}\))  
- **Asignaci贸n**:  
  \[
  \mathcal{T}[k][1] = \{\text{"Borrador"}\}, \quad \mathcal{T}[k][2] = \emptyset, \quad \mathcal{T}[k][3] = \emptyset
  \]  

---

### **S贸lidez del Modelo Ajustado**  
1. **Generalidad**:  
   - Combina **m茅tricas geom茅tricas** (distancias, centroides) con **heur铆sticas robustas** (cortes por espacios).  
2. **Optimalidad local**:  
   - En \(L_k \geq H\), los cortes maximizan la separaci贸n visual entre columnas.  
3. **Sem谩ntica impl铆cita**:  
   - La similitud de centroides en \(L_k = 1\) preserva alineaci贸n vertical aunque no haya separaci贸n clara.  

**Nota**: Este modelo formaliza la implementaci贸n real del c贸digo, donde la geometr铆a prima sobre supuestos ideales de alineaci贸n perfecta.

### ** Planteamiento Formal Actualizado: Segmentaci贸n en el Espacio Vectorial \( S_k \)**

---

#### **1. Definici贸n del Espacio Vectorial \( S_k \)**
- **Base del espacio**:  
  Cada elemento \( P_i \in S_k \) se representa como un vector en \( \mathbb{R}^m \):  
  \[
  \vec{v}_i = \left( x_i, z_i, \gamma_i^1, \gamma_i^2, \dots, \gamma_i^{m-2} \right)
  \]  
  Donde:  
  - \( x_i \): Posici贸n horizontal (coordenada geom茅trica).  
  - \( z_i \): Embedding estrat茅gico (codificador num茅rico).  
  - \( \gamma_i^j \): Atributos enriquecidos (ancho, confianza OCR, etc.).  

- **Propiedades**:  
  - **Orden lineal**: \( x_i < x_{i+1} \) (Axioma 1).  
  - **M茅trica de similitud**:  
    \[
    d(\vec{v}_i, \vec{v}_j) = \cos(\vec{v}_i, \vec{v}_j) \quad \text{(similitud del coseno)}.
    \]

---

#### **2. Proceso de Segmentaci贸n en \( S_k \)**

##### **Paso 1: Agrupamiento Local con Ventana Impar**
- **Ventana \( W_t \)**:  
  Subconjunto de \( w \) vectores consecutivos (\( w \) impar):  
  \[
  W_t = \{ \vec{v}_{t-\lfloor w/2 \rfloor}, \dots, \vec{v}_{t+\lfloor w/2 \rfloor} \}
  \]  
- **Medida de cohesi贸n**:  
  \[
  S(W_t) = \frac{1}{|W_t|^2} \sum_{\vec{v}_i, \vec{v}_j \in W_t} \cos(\vec{v}_i, \vec{v}_j)
  \]  
  - Si \( S(W_t) < \theta \), \( t \) es un **punto de ruptura candidato**.

##### **Paso 2: Selecci贸n de \( H-1 \) Rupturas ptimas**
1. **Ranking de rupturas**:  
   Ordenar todos los puntos \( t \) por \( S(W_t) \) ascendente.  
2. **Cortes finales**:  
   Seleccionar los \( H-1 \) puntos con menor \( S(W_t) \).  
   \[
   \mathcal{J} = \{ j_1, j_2, \dots, j_{H-1} \} \quad \text{(ordenados por \( x \))}
   \]  

##### **Paso 3: Asignaci贸n a Columnas**
- **Regla de asignaci贸n**:  
  Para cada \( \vec{v}_i \in S_k \):  
  \[
  C(\vec{v}_i) = \begin{cases}
  1 & \text{si } x_i \leq j_1, \\
  h & \text{si } j_{h-1} < x_i \leq j_h \quad (1 < h < H), \\
  H & \text{si } x_i > j_{H-1}.
  \end{cases}
  \]  

---

#### **3. Teorema de Consistencia Ajustado**

**Hip贸tesis**:  
1. **Separabilidad en \( S_k \)**:
   - Los vectores de distintas columnas forman clusters distinguibles en \( \mathbb{R}^m \).  
2. **Discontinuidades claras**:  
   - Existen \( H-1 \) hiperplanos en \( S_k \) que maximizan la cohesi贸n intra-columna.  

**Tesis**:  
El m茅todo garantiza:  
1. **Preservaci贸n de \( H \)**:  
   \[
   |\{ C_1, \dots, C_H \}| = H \quad \text{(sin columnas vac铆as)}.
   \]  
2. **Optimalidad local**:  
   Los cortes \( \mathcal{J} \) minimizan la varianza intra-columna:  
   \[
   \sum_{h=1}^H \text{Var}(\{ \vec{v}_i \}_{i \in C_h}) \quad \text{es m铆nima}.
   \]  

---

#### **4. Ejemplo en \( \mathbb{R}^3 \) (con \( \gamma_i = \) ancho del bbox)**
**Datos**:  
\[
S_k = \left\{ 
  \vec{v}_1 = (10, 95, 20), \quad \vec{v}_2 = (30, 2, 10), \quad \vec{v}_3 = (50, 8.5, 30) 
\right\}
\]  
**Proceso**:  
1. **Ventana \( W_2 \)**:  
   - \( \cos(\vec{v}_1, \vec{v}_2) \approx 0.1 \), \( \cos(\vec{v}_2, \vec{v}_3) \approx 0.3 \).  
   - \( S(W_2) = 0.2 \) (ruptura fuerte).  
2. **Corte**: \( \mathcal{J} = \{30\} \).  
3. **Columnas**:  
   \[
   C_1 = \{ \vec{v}_1 \}, \quad C_2 = \{ \vec{v}_2 \}, \quad C_3 = \{ \vec{v}_3 \}.
   \]  

---

#### **5. Ventajas Clave**  
- **Espacio de caracter铆sticas flexible**:  
  Acepta cualquier \( \gamma_i^j \) relevante (ej: confianza OCR, 谩rea, etc.).  
- **Sin dependencia externa**:  
  No requiere entrenamiento ni conocimiento sem谩ntico.  
- **Interpretabilidad geom茅trica**:  
  Los cortes corresponden a discontinuidades naturales en \( S_k \).  

---

#### **6. L铆mites y Extensiones**  
| **Caso L铆mite**          | **Soluci贸n**                                  |  
|---------------------------|---------------------------------------------|  
| **\( H \) desconocido**   | Inferir \( H \) con clustering jer谩rquico en \( S_k \). |  
| **Ruido en \( \gamma \)** | Usar medianas m贸viles o suavizado espacial. |  
| **Solapamientos**         | Penalizar \( \cos(\cdot) \) en zonas de alta densidad. |  

---

### ** Conclusi贸n**  
Este planteamiento formaliza la segmentaci贸n en \( S_k \) como un **problema de optimizaci贸n en espacio vectorial**, combinando:  
1. **Geometr铆a** (posici贸n \( x \)).  
2. **Embeddings estrat茅gicos** (\( z \)).  
3. **Atributos enriquecidos** (\( \gamma \)).  

**Implementaci贸n**:  
```python
def segmentar_en_Sk(S_k: List[Vector], H: int) -> List[List[Vector]]:
    # 1. Calcular rupturas con ventana impar
    rupturas = detectar_rupturas(S_k, w=3, theta=0.5)
    # 2. Seleccionar H-1 cortes
    cortes = sorted(rupturas, key=lambda x: x.score)[:H-1]
    # 3. Asignar a columnas
    return asignar_columnas(S_k, cortes)
```  

**Nota**: Para datos reales, ajustar \( \theta \) y \( w \) seg煤n la densidad de \( S_k \).